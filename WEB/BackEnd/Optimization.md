# Optimization


## 개요

지금까지 구현했던 서비스들은 단순하고 일단 구현만 하면 되는 프로젝트였다. 좀 더 고민을 발전시켜서 대규모의 트레픽이 있을 경우 우리의 프로젝트들은 어떤 문제가 있을까 생각해보려한다.

## 비용

웹에는 비용이 비싼 작업들이 있다. 여기서 비용이란 무언가 작업을 할 때 리소스나 시간을 많이 들이는 작업을 말한다.

예를 들어 새로고침을 한다던지 외부 API를 호출한다던지 db와 커넥션을 맺는다던지 등의 작업들은 비용이 비싸다.

이런 작업들의 로직을 좀 더 최적화할 필요가 있다.

작은 문제가 큰 문제로 퍼지는 걸 막기 위해서다.

## 중복된 코드들

게시글을 작성하는 경우를 예로 들면 서비스 부분에서 유저의 정보를 읽어들여 게시글을 db에 저장할 때 작성한 유저의 정보를 게시글 정보에 넣어주는 로직이 있다고 하자.

그렇다면 서비스 내에서 findByUsername과 같은 메소드를 실행시키고 유저의 정보를 받아와서 게시글 엔티티 객체에 set해주면 된다.

그러나 유저의 요청은 이미 필터를 거쳐 왔기 때문에 서버는 유저에 대한 정보를 알고있다. 이 정보를 이용할 순 없을까?

로그인한 유저가 서비스에서 여러 활동을 할텐데 이 때마다 유저의 정보를 조회한다. 유저라는 정보가 쉽게 변경되는 부분이 아닐 수 있다. 매 API요청마다 조회한다면 비효율적이다.

꼭 당장 응답을 해줘야하는가?

우리가 어떤 게시물에 좋아요를 누를 때 게시글을 작성한 유저에게 반드시 당장 알림이 가야할까? 

한 게시글에 좋아요를 중복해서 여러번 누를 순 없다. 이를 위한 체크 로직이 하나 필요할 것이고 이 좋아요 기록을 db에 저장하는 로직이 필요하고 게시글 작성자에게 이 사실을 알려주는 로직이 있다고한다. 

만약 첫번째 작업이 5초가 걸린다고 가정해보자 이 시간은 당연히 기다려야하는 시간이다.

그리고 좋아요를 db에 저장하는 것 역시 비즈니스로직으로 기다려야한다.

그러나 알림로직은 좀 다른데 알람을 보내는 것 자체는 기다릴 필요가 없다. 조금의 지연이 용납된다.

그러나 일반적인 코드는 알림까지 생성해야 응답이 간다.

우리가 던지는 쿼리들은 최적화가 되어있을까?

좀더 효율적인 경로의 쿼리는 없을까?

## 해결책

만약 1초에 100만명의 유저가 로그인을 시도한다고 했을 때 db엔 100만건의 io가 날라간다.

변하지 않는 데이터를 매번 db에 요청해서 가져올 필요없이 중간에 캐시를(Redis) 붙여서 dbio를 줄이는 방식을 고려해볼 수 있겠다.

알림이 완성이 되어야 응답이 되는 부분은 kafka를 사용해서 비동기 방식을 사용해보는 방법을 고려해볼 수 있겠다.




