# Intro

## 필요성

서버를 개발해서 배포를 하려고 한다. 만약 이 서비스가 사용자들의 니즈랑 맞아서 사용자가 많아진다면 어떻게 될까? 서버에는 많은 요청이 전송될 것이고 서버의 자원은 한정적이다. 그렇기 때문에 서버에 부하가 증가한다. 많은 요청을 처리하기 위해선 많은 서버가 필요하다. 서버가 너무 조금 증설한다면 여전히 문제가 해결되지 않을 것이고 서버를 너무 많이 증설한다면 불필요한 비용이 지출될 것이다.

이러한 상황에 대한 시뮬레이션을 해볼 수 있는 방법이 바로 성능 테스트이다.

그럼 이 성능 테스트툴을 이용해 얼마나 많은 수의 서버가 필요한지 테스트해볼 수 있고 현재 구조에서 처리할 수 있는 최대치가 어느정도인지 테스트해볼 수 있다.

그리고 이러한 테스트는 서버 내부의 문제를 발견하는 데도 큰 도움이 된다. 대표적으로 GC가 있다.

컨벤션이 중요한 이유 중 하나는 이와 같은 개발자의 개인의 코드 습관이 작은 차이를 발생시키고 당장은 별 문제가 없어 보여도 트래픽이 증가하는 상황에선 작은 차이들이 누적되어 문제를 일으킬 수 있기 때문이기도 하다. 이런 부분을 성능 테스트로도 발견할 수 있다. 단순 요청의 경우에는 발견하기 힘들지만 이렇게 서버에 많은 요청을 보내보면 확인할 수 있다.

또 성능테스트를 통해 데이터베이스의 성능 개선을 계획해볼 수 있다.

막간을 이용해서 성능 테스트의 종류를 정리해보자

성능 테스트에는 여러 종류가 있다.

* 부하테스트 : 시스템에 부하를 계속 증가시키면서 시슽템의 임계점을 찾는 테스트. 테스트 결과를 분석해 병목 지점을 찾고 제거하는 과정을 반복한다.

* 강도 테스트 : 임계점 이상의 부하를 가해서 비정상적인 상황에서의 시스템 동작 상태를 확인하는 테스트
* 스파이크 테스트 : 짧은 시간에 사용자가 몰릴 때 시스템의 반응 측정 테스트
* 내구성 테스트 : 오랜 시간 동안 시스템에 높은 부하를 가하여 시스템 반응 테스트

이상이다.

## 지연시간과 처리량

지연시간이란 클라이언트가 요청을 보낸 후 응답을 받기까지 걸린 시간을 말한다. 만약 사용자가 요청을 보내고 응답을 받기까지 1초가 걸린다면 지연시간이 1초인 것이다

일반적으로는 ms(밀리 세컨즈)단위를 사용한다.

처리량이란 단위 시간동안 얼마나 많은 요청을 처리할 수 있는지를 말한다.

단위 시간이란 1초를 주로 사용한다. tps Transaction Per Second

만약 1초동안 1000개의 요청을 처리했다면 1tps라고 할 수 있다.

성능을 측절할 땐 처리량과 지연시간 모두 고려를 해야한다. 초당 3000개의 요청이 들어올 때 99%의 요청이 100ms 미만으로 처리되어야함.

100%의 요청을 모두 100ms 미만으로 처리하는 것은 불가능에 가깝기 때문이다.

일반적으로 처리량이 적으면 지연시간이 줄어들고 처리량을 높이면 지연시간이 늘어난다.(서버의 자원은 한정되어있기 때문이다.)

## 운영체제

서버의 물리적인 자원을 관리하며 프로세스라는 단위로 애플리케이션을 실행시킴.

서버에서 주로 사용되는 운영체제는 리눅스이다.

주요 자원은 cpu, 메모리, 디스크가 있다.

운영체제는 애플리케이션을 프로세스로 생성해서 관리하게된다.

프로세스는 필요한 자원을 할당받아서 동작한다.

개발자가 작성한 애플리케이션은 이러한 자원들을 사용한다.

이 자원들은 모두 각각의 자원으로 애플리케이션의 특징에 따라 더 많이 쓰이는 자원이 달라질 수 있다.

프로그램 : 디스크에 저장되어있는 실행할 수 있는 파일이나 소프트웨어의 집합을 말한다.

프로그램을 실행시키면 메모리에 올라와서 실행이된다. 이를 프로세스라고 부른다. 메모리 + 코드 코드에 따라서 메모리에 값을 할당하거나 한다.

cpu는 프로세스에 정의된 코드를 실행시킨다.

이 과정에서 프로세스와 cpu가 서로 상호작용한다.

메모리와 디스크가 상호작용 가상 메모리

실행되는 프로세스가 많아지면 물리적인 ram 위에 모든 프로세스를 올릴 수 없다. 이를 해결하기 위해 물리적인 메모리를 디스크에 일부 저장했다가 다시 불러온다.(페이징)

cpu 계산작업. 이미지, 영상 인코딩 암호화, 해시화.

인스턴스를 대량 생성하는 경우 메모리를 많이 씀.

GC가 빈번하게 일어난다. 이런 과정에서 cpu가 개입하여 사용하는 인스턴스인지 아닌지 체크.

파일 입출력, 로그 발생 -> 파일

## 네트워크

클라이언트는 서버에 요청을 보내고 서버는 데이터베이스 호출이나 다른 API를 호출한다.

이 과정에서 네트워크 통신이 일어난다.

일반적인 서버 내부의 자원을 사용하는 작업들은 실행 완료까지 1ms를 넘어가지 않는다. 반면 네트워크 통신은 대부분의 경우 1ms를 넘는다.

따라서 네트워크 통신은 비용이 매우 비싼 작업이다.

네트워크 통신은 마법이 아니다. 빛의 속도는 약 30만 km/s이고 한국의 지구 반대편에 위치한 나라는 우루과이이다.

한국과 우루과이 상호간에 통신을 한다면 요청 시 지구 반바퀴 응답 시 지구 반바퀴를 거쳐서 지구 한바퀴를 도는 것이다.

빛이 1바퀴를 토는데 133.3ms가 걸린다.

그러나 133.3ms는 최소 시간이고 실제론 더 오래걸릴 것으로 예상할 수 있다. 

예를 들어 국내 사이트로 Ping 명령어를 통해 측정해봤을 때와 우루과이의 opcion.com.uy로 측정해봤을 때의 시간이 크게 차이나는 것을 볼 수 있다.

## 데이터베이스

10건 중 1건을 찾는 경우와 1억 건 중 1건을 찾는 경우는 분명한 차이가 있을 것이다.

트랜잭션을 지원하기 위해 데이터에 락이 걸린다.

락이 걸리는 만큼 대기시간이 발생하고 때로는 데드락이 발생하여 응답이 처리되지 않기도 하다.


## 방향성

실무서가 아닌 경우에는 방향성을 조금 다르게 잡아야한다.

실무일 경우 인프라 자원을 늘려서 문제를 해겷할 수 있지만 실무가 아닌 경우에서는 인프라 자원을 늘리기가 어렵다. 

우선 예상되는 트래픽이 존재하지 않을 것이며 임의로 목표를 정한다고 해도 충분한 인프라 자원을 투입하기가 어렵다. 우리의 사비로 서버 비용을 지불해야하기 때문이다.

1. 한 건씩 요청을 보내서 지연시간 측정하기
2. 처리량을 높이면서 현재 상태에서 지연시간이 치솟는 지점을 찾아보기
3. 테스트를 반복하며 어떤 부분에서 병목현상이 일어나는지 가설을 세워보고 모니터링, 로그 등을 통해 특정한다.
4. 병목 현상을 해결할 수 있는 방법을 적용해본다.
